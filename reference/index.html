
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://mackelab.org/sbi/reference/" rel="canonical"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.1.2, mkdocs-material-5.2.2" name="generator"/>
<title>API Reference - sbi</title>
<link href="../assets/stylesheets/main.a2408e81.min.css" rel="stylesheet"/>
<link href="../assets/stylesheets/palette.a46bcfb3.min.css" rel="stylesheet"/>
<meta content="#3f51b5" name="theme-color"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
<link href="../static/global.css" rel="stylesheet"/>
<link href="../css/ansi-colours.css" rel="stylesheet"/>
<link href="../css/jupyter-cells.css" rel="stylesheet"/>
<link href="../css/pandas-dataframe.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#api-reference">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header-nav md-grid">
<a aria-label="sbi" class="md-header-nav__button md-logo" href="https://mackelab.org/sbi/" title="sbi">
<img alt="logo" src="../static/logo.svg"/>
</a>
<label class="md-header-nav__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header-nav__title" data-md-component="header-title">
<div class="md-header-nav__ellipsis">
<span class="md-header-nav__topic md-ellipsis">
            sbi
          </span>
<span class="md-header-nav__topic md-ellipsis">
            
              API Reference
            
          </span>
</div>
</div>
<label class="md-header-nav__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</label>
<button aria-label="Clear" class="md-search__icon md-icon" data-md-component="search-reset" tabindex="-1" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"></path></svg>
</button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header-nav__source">
<a class="md-source" href="http://github.com/mackelab/sbi/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    mackelab/sbi
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="sbi" class="md-nav__button md-logo" href="https://mackelab.org/sbi/" title="sbi">
<img alt="logo" src="../static/logo.svg"/>
</a>
    sbi
  </label>
<div class="md-nav__source">
<a class="md-source" href="http://github.com/mackelab/sbi/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    mackelab/sbi
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href=".." title="Home">
      Home
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../install/" title="Installation">
      Installation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="https://github.com/mackelab/sbi/blob/master/examples/HH_simulator.ipynb" target="_blank" title="Tutorial">
      Tutorial
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../contribute/" title="Contribute">
      Contribute
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        API Reference
        <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"></path></svg>
</span>
</label>
<a class="md-nav__link md-nav__link--active" href="./" title="API Reference">
      API Reference
    </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference">
    Inference
  </a>
<nav aria-label="Inference" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_a.SnpeA">
    SnpeA
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_b.SnpeB">
    SnpeB
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_c.SnpeC">
    SnpeC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snl.snl.SNL">
    SNL
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.sre.sre.SRE">
    SRE
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models">
    Models
  </a>
<nav aria-label="Models" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.posterior_nn">
    posterior_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.likelihood_nn">
    likelihood_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.classifier_nn">
    classifier_nn()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../credits/" title="Credits">
      Credits
    </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference">
    Inference
  </a>
<nav aria-label="Inference" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_a.SnpeA">
    SnpeA
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_b.SnpeB">
    SnpeB
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_c.SnpeC">
    SnpeC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snl.snl.SNL">
    SNL
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.sre.sre.SRE">
    SRE
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models">
    Models
  </a>
<nav aria-label="Models" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.posterior_nn">
    posterior_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.likelihood_nn">
    likelihood_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.classifier_nn">
    classifier_nn()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="http://github.com/mackelab/sbi/edit/master/docs/reference.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>
<h1 id="api-reference">API Reference<a class="headerlink" href="#api-reference" title="Permanent link">¶</a></h1>
<h2 id="inference">Inference<a class="headerlink" href="#inference" title="Permanent link">¶</a></h2>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snpe.snpe_a.SnpeA">
<code>sbi.inference.snpe.snpe_a.SnpeA</code>
<a class="headerlink" href="#sbi.inference.snpe.snpe_a.SnpeA" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snpe.snpe_a.SnpeA.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">z_score_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">z_score_min_std</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">skip_input_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>SNPE-A [1] - CURRENTLY NOT IMPLEMENTED.</p>
<p>[1] <em>Fast epsilon-free Inference of Simulation Models with Bayesian Conditional
    Density Estimation</em>, Papamakarios et al., NeurIPS 2016,
    <a href="https://arxiv.org/abs/1605.06376">https://arxiv.org/abs/1605.06376</a>.</p>
<p>See docstring of <code>SnpeBase</code> class for all other arguments.</p>
<details class="quote">
<summary>Source code in <code>sbi/inference/snpe/snpe_a.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">x_o</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">z_score_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">z_score_min_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">discard_prior_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SummaryWriter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">skip_input_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">"""SNPE-A [1] - CURRENTLY NOT IMPLEMENTED.</span>

<span class="sd">    [1] _Fast epsilon-free Inference of Simulation Models with Bayesian Conditional</span>
<span class="sd">        Density Estimation_, Papamakarios et al., NeurIPS 2016,</span>
<span class="sd">        https://arxiv.org/abs/1605.06376.</span>

<span class="sd">    See docstring of `SnpeBase` class for all other arguments.</span>
<span class="sd">    """</span>

    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snpe.snpe_b.SnpeB">
<code>sbi.inference.snpe.snpe_b.SnpeB</code>
<a class="headerlink" href="#sbi.inference.snpe.snpe_b.SnpeB" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snpe.snpe_b.SnpeB.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calibration_kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">z_score_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">z_score_min_std</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">worker_batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">skip_input_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_progressbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_round_summary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logging_level</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>SNPE-B [1]</p>
<p>[1] <em>Flexible statistical inference for mechanistic models of neural dynamics</em>,
    Lueckmann et al., NeurIPS 2017, <a href="https://arxiv.org/abs/1711.01861">https://arxiv.org/abs/1711.01861</a>.</p>
<p>See docstring of <code>SnpeBase</code> class for all other arguments.</p>
<details class="quote">
<summary>Source code in <code>sbi/inference/snpe/snpe_b.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">x_o</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calibration_kernel</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">z_score_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">z_score_min_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">discard_prior_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SummaryWriter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">worker_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">skip_input_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">show_progressbar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">show_round_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""SNPE-B [1]</span>

<span class="sd">    [1] _Flexible statistical inference for mechanistic models of neural dynamics_,</span>
<span class="sd">        Lueckmann et al., NeurIPS 2017, https://arxiv.org/abs/1711.01861.</span>

<span class="sd">    See docstring of `SnpeBase` class for all other arguments.</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">x_o</span><span class="o">=</span><span class="n">x_o</span><span class="p">,</span>
        <span class="n">density_estimator</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">calibration_kernel</span><span class="o">=</span><span class="n">calibration_kernel</span><span class="p">,</span>
        <span class="n">z_score_x</span><span class="o">=</span><span class="n">z_score_x</span><span class="p">,</span>
        <span class="n">z_score_min_std</span><span class="o">=</span><span class="n">z_score_min_std</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="o">=</span><span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="n">retrain_from_scratch_each_round</span><span class="p">,</span>
        <span class="n">discard_prior_samples</span><span class="o">=</span><span class="n">discard_prior_samples</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">worker_batch_size</span><span class="o">=</span><span class="n">worker_batch_size</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">skip_input_checks</span><span class="o">=</span><span class="n">skip_input_checks</span><span class="p">,</span>
        <span class="n">show_progressbar</span><span class="o">=</span><span class="n">show_progressbar</span><span class="p">,</span>
        <span class="n">show_round_summary</span><span class="o">=</span><span class="n">show_round_summary</span><span class="p">,</span>
        <span class="n">logging_level</span><span class="o">=</span><span class="n">logging_level</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snpe.snpe_c.SnpeC">
<code>sbi.inference.snpe.snpe_c.SnpeC</code>
<a class="headerlink" href="#sbi.inference.snpe.snpe_c.SnpeC" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snpe.snpe_c.SnpeC.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="n">num_atoms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calibration_kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">z_score_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">z_score_min_std</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">worker_batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_with_mcmc</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mcmc_method</span><span class="o">=</span><span class="s1">'slice_np'</span><span class="p">,</span> <span class="n">skip_input_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_progressbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_round_summary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logging_level</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>SNPE-C / APT [1]</p>
<p>[1] <em>Automatic Posterior Transformation for Likelihood-free Inference</em>,
    Greenberg et al., ICML 2019, <a href="https://arxiv.org/abs/1905.07488">https://arxiv.org/abs/1905.07488</a>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>use_combined_loss</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to train the neural net jointly on prior samples
using maximum likelihood and on all samples using atomic loss. Useful
to prevent density leaking when using bounded priors.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>num_atoms</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Number of atoms to use for classification. If None, use all
other parameters <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> in minibatch.</p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>See docstring of <code>SnpeBase</code> class for all other arguments.</p>
<details class="quote">
<summary>Source code in <code>sbi/inference/snpe/snpe_c.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">x_o</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">num_atoms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calibration_kernel</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">use_combined_loss</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">z_score_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">z_score_min_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">discard_prior_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SummaryWriter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">worker_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_with_mcmc</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">mcmc_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"slice_np"</span><span class="p">,</span>
    <span class="n">skip_input_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">show_progressbar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">show_round_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""SNPE-C / APT [1]</span>

<span class="sd">    [1] _Automatic Posterior Transformation for Likelihood-free Inference_,</span>
<span class="sd">        Greenberg et al., ICML 2019, https://arxiv.org/abs/1905.07488.</span>

<span class="sd">    Args:</span>
<span class="sd">        use_combined_loss: Whether to train the neural net jointly on prior samples</span>
<span class="sd">            using maximum likelihood and on all samples using atomic loss. Useful</span>
<span class="sd">            to prevent density leaking when using bounded priors.</span>
<span class="sd">        num_atoms: Number of atoms to use for classification. If None, use all</span>
<span class="sd">            other parameters $\theta$ in minibatch.</span>

<span class="sd">    See docstring of `SnpeBase` class for all other arguments.</span>
<span class="sd">    """</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_num_atoms</span> <span class="o">=</span> <span class="n">num_atoms</span> <span class="k">if</span> <span class="n">num_atoms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_use_combined_loss</span> <span class="o">=</span> <span class="n">use_combined_loss</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">x_o</span><span class="o">=</span><span class="n">x_o</span><span class="p">,</span>
        <span class="n">density_estimator</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">calibration_kernel</span><span class="o">=</span><span class="n">calibration_kernel</span><span class="p">,</span>
        <span class="n">z_score_x</span><span class="o">=</span><span class="n">z_score_x</span><span class="p">,</span>
        <span class="n">z_score_min_std</span><span class="o">=</span><span class="n">z_score_min_std</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="o">=</span><span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="n">retrain_from_scratch_each_round</span><span class="p">,</span>
        <span class="n">discard_prior_samples</span><span class="o">=</span><span class="n">discard_prior_samples</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">sample_with_mcmc</span><span class="o">=</span><span class="n">sample_with_mcmc</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">worker_batch_size</span><span class="o">=</span><span class="n">worker_batch_size</span><span class="p">,</span>
        <span class="n">skip_input_checks</span><span class="o">=</span><span class="n">skip_input_checks</span><span class="p">,</span>
        <span class="n">show_progressbar</span><span class="o">=</span><span class="n">show_progressbar</span><span class="p">,</span>
        <span class="n">show_round_summary</span><span class="o">=</span><span class="n">show_round_summary</span><span class="p">,</span>
        <span class="n">logging_level</span><span class="o">=</span><span class="n">logging_level</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snl.snl.SNL">
<code>sbi.inference.snl.snl.SNL</code>
<a class="headerlink" href="#sbi.inference.snl.snl.SNL" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__call__()" id="sbi.inference.snl.snl.SNL.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_rounds</span><span class="p">,</span> <span class="n">num_simulations_per_round</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stop_after_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_max_norm</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Run SNL</p>
<p>This runs SNL for num_rounds rounds, using num_simulations_per_round calls to
the simulator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_rounds</code></td>
<td><code>int</code></td>
<td>
<p>Number of rounds to run</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>num_simulations_per_round</code></td>
<td><code>OneOrMore[int]</code></td>
<td>
<p>Number of simulator calls per round</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>int</code></td>
<td>
<p>Size of batch to use for training.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>learning_rate</code></td>
<td><code>float</code></td>
<td>
<p>Learning rate for Adam optimizer.</p>
</td>
<td><code>0.0005</code></td>
</tr>
<tr>
<td><code>validation_fraction</code></td>
<td><code>float</code></td>
<td>
<p>The fraction of data to use for validation.</p>
</td>
<td><code>0.1</code></td>
</tr>
<tr>
<td><code>stop_after_epochs</code></td>
<td><code>int</code></td>
<td>
<p>The number of epochs to wait for improvement on the
validation set before terminating training.</p>
</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>max_num_epochs</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Maximum number of epochs to run. If max_num_epochs
is reached, we stop training even if the validation loss is still
decreasing. If None, we train until validation loss increases (see
argument stop_after_epochs).</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>clip_max_norm</code></td>
<td><code>Optional[float]</code></td>
<td>
<p>Value at which to clip the total gradient norm in order to
prevent exploding gradients. Use None for no clipping.</p>
</td>
<td><code>5.0</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>NeuralPosterior</code></td>
<td>
<p>Posterior <span><span class="MathJax_Preview">p(\theta|x_o)</span><script type="math/tex">p(\theta|x_o)</script></span> that can be sampled and evaluated</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/snl/snl.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_rounds</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_simulations_per_round</span><span class="p">:</span> <span class="n">OneOrMore</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-4</span><span class="p">,</span>
    <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">stop_after_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">max_num_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">clip_max_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NeuralPosterior</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">"""Run SNL</span>

<span class="sd">    This runs SNL for num_rounds rounds, using num_simulations_per_round calls to</span>
<span class="sd">    the simulator</span>

<span class="sd">    Args:</span>
<span class="sd">        num_rounds: Number of rounds to run</span>
<span class="sd">        num_simulations_per_round: Number of simulator calls per round</span>
<span class="sd">        batch_size: Size of batch to use for training.</span>
<span class="sd">        learning_rate: Learning rate for Adam optimizer.</span>
<span class="sd">        validation_fraction: The fraction of data to use for validation.</span>
<span class="sd">        stop_after_epochs: The number of epochs to wait for improvement on the</span>
<span class="sd">            validation set before terminating training.</span>
<span class="sd">        max_num_epochs: Maximum number of epochs to run. If max_num_epochs</span>
<span class="sd">            is reached, we stop training even if the validation loss is still</span>
<span class="sd">            decreasing. If None, we train until validation loss increases (see</span>
<span class="sd">            argument stop_after_epochs).</span>
<span class="sd">        clip_max_norm: Value at which to clip the total gradient norm in order to</span>
<span class="sd">            prevent exploding gradients. Use None for no clipping.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Posterior $p(\theta|x_o)$ that can be sampled and evaluated</span>
<span class="sd">    """</span>

    <span class="n">max_num_epochs</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">31</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">max_num_epochs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_num_epochs</span>

    <span class="n">num_sims_per_round</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_list</span><span class="p">(</span><span class="n">num_simulations_per_round</span><span class="p">,</span> <span class="n">num_rounds</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">round_</span><span class="p">,</span> <span class="n">num_sims</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_sims_per_round</span><span class="p">):</span>

        <span class="c1"># Generate parameters theta from prior in first round, and from most recent</span>
        <span class="c1"># posterior estimate in subsequent rounds.</span>
        <span class="k">if</span> <span class="n">round_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">num_sims</span><span class="p">,))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                <span class="n">num_sims</span><span class="p">,</span> <span class="n">show_progressbar</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_show_progressbar</span>
            <span class="p">)</span>

        <span class="c1"># why do we return theta just below? When using multiprocessing, the thetas</span>
        <span class="c1"># are not handled sequentially anymore. Hence, the x that are returned do</span>
        <span class="c1"># not necessarily have the same order as the theta we define above. We</span>
        <span class="c1"># therefore return a theta vector with the same ordering as x.</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batched_simulator</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="c1"># Store (theta, x) pairs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_theta_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_x_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Fit neural likelihood to newly aggregated dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span>
            <span class="n">stop_after_epochs</span><span class="o">=</span><span class="n">stop_after_epochs</span><span class="p">,</span>
            <span class="n">max_num_epochs</span><span class="o">=</span><span class="n">max_num_epochs</span><span class="p">,</span>
            <span class="n">clip_max_norm</span><span class="o">=</span><span class="n">clip_max_norm</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update description for progress bar.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_show_round_summary</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_describe_round</span><span class="p">(</span><span class="n">round_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">))</span>

        <span class="c1"># Update TensorBoard and summary dict.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summarize</span><span class="p">(</span>
            <span class="n">round_</span><span class="o">=</span><span class="n">round_</span><span class="p">,</span>
            <span class="n">x_o</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_x_o</span><span class="p">,</span>
            <span class="n">theta_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_theta_bank</span><span class="p">,</span>
            <span class="n">x_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_x_bank</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span><span class="o">.</span><span class="n">_num_trained_rounds</span> <span class="o">=</span> <span class="n">num_rounds</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snl.snl.SNL.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">worker_batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">mcmc_method</span><span class="o">=</span><span class="s1">'slice_np'</span><span class="p">,</span> <span class="n">skip_input_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_progressbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_round_summary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logging_level</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Sequential Neural Likelihood</p>
<p>Sequential Neural Likelihood: Fast Likelihood-free Inference with
Autoregressive Flows_ by Papamakarios et al., AISTATS 2019,
<a href="https://arxiv.org/abs/1805.07226">https://arxiv.org/abs/1805.07226</a></p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>density_estimator</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Conditional density estimator <span><span class="MathJax_Preview">q(x|\theta)</span><script type="math/tex">q(x|\theta)</script></span>, a nn.Module
with <code>.log_prob()</code> and <code>.sample()</code></p>
</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>See docstring of <code>NeuralInference</code> class for all other arguments.</p>
<details class="quote">
<summary>Source code in <code>sbi/inference/snl/snl.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">x_o</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SummaryWriter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">worker_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">mcmc_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"slice_np"</span><span class="p">,</span>
    <span class="n">skip_input_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">show_progressbar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">show_round_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""Sequential Neural Likelihood</span>

<span class="sd">    Sequential Neural Likelihood: Fast Likelihood-free Inference with</span>
<span class="sd">    Autoregressive Flows_ by Papamakarios et al., AISTATS 2019,</span>
<span class="sd">    https://arxiv.org/abs/1805.07226</span>

<span class="sd">    Args:</span>
<span class="sd">        density_estimator: Conditional density estimator $q(x|\theta)$, a nn.Module</span>
<span class="sd">            with `.log_prob()` and `.sample()`</span>

<span class="sd">    See docstring of `NeuralInference` class for all other arguments.</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="p">,</span>
        <span class="n">x_o</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">device</span><span class="p">,</span>
        <span class="n">summary_writer</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">worker_batch_size</span><span class="o">=</span><span class="n">worker_batch_size</span><span class="p">,</span>
        <span class="n">skip_input_checks</span><span class="o">=</span><span class="n">skip_input_checks</span><span class="p">,</span>
        <span class="n">show_progressbar</span><span class="o">=</span><span class="n">show_progressbar</span><span class="p">,</span>
        <span class="n">show_round_summary</span><span class="o">=</span><span class="n">show_round_summary</span><span class="p">,</span>
        <span class="n">logging_level</span><span class="o">=</span><span class="n">logging_level</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">density_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">density_estimator</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">likelihood_nn</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">"maf"</span><span class="p">,</span>
            <span class="n">theta_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">x_o_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_x_o</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># create neural posterior which can sample()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span> <span class="o">=</span> <span class="n">NeuralPosterior</span><span class="p">(</span>
        <span class="n">algorithm_family</span><span class="o">=</span><span class="s2">"snl"</span><span class="p">,</span>
        <span class="n">neural_net</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">x_o</span><span class="o">=</span><span class="n">x_o</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
        <span class="n">get_potential_function</span><span class="o">=</span><span class="n">PotentialFunctionProvider</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="c1"># XXX why not density_estimator.train(True)???</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># SNL-specific summary_writer fields</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"mcmc_times"</span><span class="p">:</span> <span class="p">[]})</span>  <span class="c1"># type: ignore</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.sre.sre.SRE">
<code>sbi.inference.sre.sre.SRE</code>
<a class="headerlink" href="#sbi.inference.sre.sre.SRE" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__call__()" id="sbi.inference.sre.sre.SRE.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_rounds</span><span class="p">,</span> <span class="n">num_simulations_per_round</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stop_after_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_max_norm</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Run SRE</p>
<p>This runs SRE for num_rounds rounds, using num_simulations_per_round calls to
the simulator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_rounds</code></td>
<td><code>int</code></td>
<td>
<p>Number of rounds to run</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>num_simulations_per_round</code></td>
<td><code>OneOrMore[int]</code></td>
<td>
<p>Number of simulator calls per round</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>int</code></td>
<td>
<p>Size of batch to use for training.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>learning_rate</code></td>
<td><code>float</code></td>
<td>
<p>Learning rate for Adam optimizer.</p>
</td>
<td><code>0.0005</code></td>
</tr>
<tr>
<td><code>validation_fraction</code></td>
<td><code>float</code></td>
<td>
<p>The fraction of data to use for validation.</p>
</td>
<td><code>0.1</code></td>
</tr>
<tr>
<td><code>stop_after_epochs</code></td>
<td><code>int</code></td>
<td>
<p>The number of epochs to wait for improvement on the
validation set before terminating training.</p>
</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>max_num_epochs</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Maximum number of epochs to run. If max_num_epochs
is reached, we stop training even if the validation loss is still
decreasing.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>clip_max_norm</code></td>
<td><code>Optional[float]</code></td>
<td>
<p>Value at which to clip the total gradient norm in order to
prevent exploding gradients. Use None for no clipping.</p>
</td>
<td><code>5.0</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>NeuralPosterior</code></td>
<td>
<p>Posterior that can be sampled and evaluated.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/sre/sre.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_rounds</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_simulations_per_round</span><span class="p">:</span> <span class="n">OneOrMore</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-4</span><span class="p">,</span>
    <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">stop_after_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">max_num_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">clip_max_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NeuralPosterior</span><span class="p">:</span>
    <span class="sd">"""Run SRE</span>

<span class="sd">    This runs SRE for num_rounds rounds, using num_simulations_per_round calls to</span>
<span class="sd">    the simulator</span>

<span class="sd">    Args:</span>
<span class="sd">        num_rounds: Number of rounds to run</span>
<span class="sd">        num_simulations_per_round: Number of simulator calls per round</span>
<span class="sd">        batch_size: Size of batch to use for training.</span>
<span class="sd">        learning_rate: Learning rate for Adam optimizer.</span>
<span class="sd">        validation_fraction: The fraction of data to use for validation.</span>
<span class="sd">        stop_after_epochs: The number of epochs to wait for improvement on the</span>
<span class="sd">            validation set before terminating training.</span>
<span class="sd">        max_num_epochs: Maximum number of epochs to run. If max_num_epochs</span>
<span class="sd">            is reached, we stop training even if the validation loss is still</span>
<span class="sd">            decreasing.</span>
<span class="sd">        clip_max_norm: Value at which to clip the total gradient norm in order to</span>
<span class="sd">            prevent exploding gradients. Use None for no clipping.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Posterior that can be sampled and evaluated.</span>
<span class="sd">    """</span>

    <span class="n">max_num_epochs</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">31</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">max_num_epochs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_num_epochs</span>

    <span class="n">num_sims_per_round</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_list</span><span class="p">(</span><span class="n">num_simulations_per_round</span><span class="p">,</span> <span class="n">num_rounds</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">round_</span><span class="p">,</span> <span class="n">num_sims</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_sims_per_round</span><span class="p">):</span>

        <span class="c1"># Generate theta from prior in first round, and from most recent posterior</span>
        <span class="c1"># estimate in subsequent rounds.</span>
        <span class="k">if</span> <span class="n">round_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">num_sims</span><span class="p">,))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                <span class="n">num_sims</span><span class="p">,</span> <span class="n">show_progressbar</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_show_progressbar</span>
            <span class="p">)</span>

        <span class="c1"># why do we return theta just below? When using multiprocessing, the thetas</span>
        <span class="c1"># are not handled sequentially anymore. Hence, the x that are returned do</span>
        <span class="c1"># not necessarily have the same order as the theta we define above. We</span>
        <span class="c1"># therefore return a theta vector with the same ordering as x.</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batched_simulator</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

        <span class="c1"># Store (theta, x) pairs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_theta_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_x_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Fit posterior using newly aggregated data set.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span>
            <span class="n">stop_after_epochs</span><span class="o">=</span><span class="n">stop_after_epochs</span><span class="p">,</span>
            <span class="n">max_num_epochs</span><span class="o">=</span><span class="n">max_num_epochs</span><span class="p">,</span>
            <span class="n">clip_max_norm</span><span class="o">=</span><span class="n">clip_max_norm</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update description for progress bar.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_show_round_summary</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_describe_round</span><span class="p">(</span><span class="n">round_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">))</span>

        <span class="c1"># Update tensorboard and summary dict.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summarize</span><span class="p">(</span>
            <span class="n">round_</span><span class="o">=</span><span class="n">round_</span><span class="p">,</span>
            <span class="n">x_o</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_x_o</span><span class="p">,</span>
            <span class="n">theta_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_theta_bank</span><span class="p">,</span>
            <span class="n">x_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_x_bank</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span><span class="o">.</span><span class="n">_num_trained_rounds</span> <span class="o">=</span> <span class="n">num_rounds</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.sre.sre.SRE.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_atoms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mcmc_method</span><span class="o">=</span><span class="s1">'slice_np'</span><span class="p">,</span> <span class="n">summary_net</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">classifier_loss</span><span class="o">=</span><span class="s1">'sre'</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">worker_batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">skip_input_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_progressbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_round_summary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logging_level</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Sequential Ratio Estimation [1]</p>
<p>[1] <em>Likelihood-free MCMC with Amortized Approximate Likelihood
    Ratios</em>, Hermans et al., Pre-print 2019, <a href="https://arxiv.org/abs/1903.04057">https://arxiv.org/abs/1903.04057</a></p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>classifier</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Binary classifier.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>num_atoms</code></td>
<td><code>Optional[int]</code></td>
<td>
<p>Number of atoms to use for classification. If None, use all
other parameters <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> in minibatch.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>retrain_from_scratch_each_round</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to retrain the conditional
density estimator for the posterior from scratch each round.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>summary_net</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Optional network which may be used to produce feature
vectors f(x) for high-dimensional simulation outputs <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>classifier_loss</code></td>
<td><code>str</code></td>
<td>
<p><code>sre</code> implements the algorithm suggested in Durkan et al.
2019, whereas <code>aalr</code> implements the algorithm suggested in
Hermans et al. 2019. <code>sre</code> can use more than two atoms, potentially
boosting performance, but does not allow for exact posterior density
evaluation (only up to a normalizing constant), even when training
only one round. <code>aalr</code> is limited to <code>num_atoms=2</code>, but allows for
density evaluation when training for one round.</p>
</td>
<td><code>'sre'</code></td>
</tr>
</tbody>
</table>
<p>See docstring of <code>NeuralInference</code> class for all other arguments.</p>
<details class="quote">
<summary>Source code in <code>sbi/inference/sre/sre.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">x_o</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">classifier</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_atoms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">mcmc_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"slice_np"</span><span class="p">,</span>
    <span class="n">summary_net</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">classifier_loss</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"sre"</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">worker_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SummaryWriter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">skip_input_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">show_progressbar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">show_round_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""Sequential Ratio Estimation [1]</span>

<span class="sd">    [1] _Likelihood-free MCMC with Amortized Approximate Likelihood</span>
<span class="sd">        Ratios_, Hermans et al., Pre-print 2019, https://arxiv.org/abs/1903.04057</span>

<span class="sd">    Args:</span>
<span class="sd">        classifier: Binary classifier.</span>
<span class="sd">        num_atoms: Number of atoms to use for classification. If None, use all</span>
<span class="sd">            other parameters $\theta$ in minibatch.</span>
<span class="sd">        retrain_from_scratch_each_round: Whether to retrain the conditional</span>
<span class="sd">            density estimator for the posterior from scratch each round.</span>
<span class="sd">        summary_net: Optional network which may be used to produce feature</span>
<span class="sd">            vectors f(x) for high-dimensional simulation outputs $x$.</span>
<span class="sd">        classifier_loss: `sre` implements the algorithm suggested in Durkan et al.</span>
<span class="sd">            2019, whereas `aalr` implements the algorithm suggested in</span>
<span class="sd">            Hermans et al. 2019. `sre` can use more than two atoms, potentially</span>
<span class="sd">            boosting performance, but does not allow for exact posterior density</span>
<span class="sd">            evaluation (only up to a normalizing constant), even when training</span>
<span class="sd">            only one round. `aalr` is limited to `num_atoms=2`, but allows for</span>
<span class="sd">            density evaluation when training for one round.</span>

<span class="sd">    See docstring of `NeuralInference` class for all other arguments.</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">x_o</span><span class="o">=</span><span class="n">x_o</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="o">=</span><span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">summary_writer</span><span class="o">=</span><span class="n">summary_writer</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">worker_batch_size</span><span class="o">=</span><span class="n">worker_batch_size</span><span class="p">,</span>
        <span class="n">skip_input_checks</span><span class="o">=</span><span class="n">skip_input_checks</span><span class="p">,</span>
        <span class="n">show_progressbar</span><span class="o">=</span><span class="n">show_progressbar</span><span class="p">,</span>
        <span class="n">show_round_summary</span><span class="o">=</span><span class="n">show_round_summary</span><span class="p">,</span>
        <span class="n">logging_level</span><span class="o">=</span><span class="n">logging_level</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_classifier_loss</span> <span class="o">=</span> <span class="n">classifier_loss</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_atoms</span> <span class="o">=</span> <span class="n">num_atoms</span> <span class="k">if</span> <span class="n">num_atoms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">classifier</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">classifier</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">classifier_nn</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">"resnet"</span><span class="p">,</span>
            <span class="n">theta_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">x_o_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_x_o</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Create posterior object which can sample().</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span> <span class="o">=</span> <span class="n">NeuralPosterior</span><span class="p">(</span>
        <span class="n">algorithm_family</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_classifier_loss</span><span class="p">,</span>
        <span class="n">neural_net</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">x_o</span><span class="o">=</span><span class="n">x_o</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
        <span class="n">get_potential_function</span><span class="o">=</span><span class="n">PotentialFunctionProvider</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_posterior</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># We may want to summarize high-dimensional x.</span>
    <span class="c1"># This may be either a fixed or learned transformation.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_summary_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span> <span class="k">if</span> <span class="n">summary_net</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">summary_net</span>

    <span class="c1"># If we're retraining from scratch each round,</span>
    <span class="c1"># keep a copy of the original untrained model for reinitialization.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_retrain_from_scratch_each_round</span> <span class="o">=</span> <span class="n">retrain_from_scratch_each_round</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_retrain_from_scratch_each_round</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_untrained_classifier</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">classifier</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_untrained_classifier</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># SRE-specific summary_writer fields.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"mcmc_times"</span><span class="p">:</span> <span class="p">[]})</span>  <span class="c1"># type: ignore</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<h2 id="models">Models<a class="headerlink" href="#models" title="Permanent link">¶</a></h2>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="sbi.utils.get_nn_models.posterior_nn">
<code class="highlight language-python">
sbi.utils.get_nn_models.posterior_nn<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_std</span><span class="p">,</span> <span class="n">x_o_shape</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">mdn_num_components</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">made_num_mixture_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">made_num_blocks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">flow_num_transforms</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> </code>
<a class="headerlink" href="#sbi.utils.get_nn_models.posterior_nn" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<p>Neural posterior density estimator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code>str</code></td>
<td>
<p>Model, one of maf / mdn / made / nsf</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>prior_mean</code></td>
<td><code>Tensor</code></td>
<td>
<p>Prior mean.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>prior_std</code></td>
<td><code>Tensor</code></td>
<td>
<p>Prior standard deviation.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x_o_numel</code></td>
<td><code></code></td>
<td>
<p>Number of elements in the a single observation.
Used as input size to the NN.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embedding</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Embedding network</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>hidden_features</code></td>
<td><code>int</code></td>
<td>
<p>For all, number of hidden features</p>
</td>
<td><code>50</code></td>
</tr>
<tr>
<td><code>mdn_num_components</code></td>
<td><code>int</code></td>
<td>
<p>For MDNs only, number of components</p>
</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>made_num_mixture_components</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of mixture components</p>
</td>
<td><code>10</code></td>
</tr>
<tr>
<td><code>made_num_blocks</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of blocks</p>
</td>
<td><code>4</code></td>
</tr>
<tr>
<td><code>flow_num_transforms</code></td>
<td><code>int</code></td>
<td>
<p>For flows only, number of transforms</p>
</td>
<td><code>5</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>nn.Module</code></td>
<td>
<p>Neural network</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/utils/get_nn_models.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">posterior_nn</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prior_mean</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">prior_std</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">x_o_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">mdn_num_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">made_num_mixture_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">made_num_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">flow_num_transforms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">"""Neural posterior density estimator</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Model, one of maf / mdn / made / nsf</span>
<span class="sd">        prior_mean: Prior mean.</span>
<span class="sd">        prior_std: Prior standard deviation.</span>
<span class="sd">        x_o_numel: Number of elements in the a single observation.</span>
<span class="sd">            Used as input size to the NN.</span>
<span class="sd">        embedding: Embedding network</span>
<span class="sd">        hidden_features: For all, number of hidden features</span>
<span class="sd">        mdn_num_components: For MDNs only, number of components</span>
<span class="sd">        made_num_mixture_components: For MADEs only, number of mixture components</span>
<span class="sd">        made_num_blocks: For MADEs only, number of blocks</span>
<span class="sd">        flow_num_transforms: For flows only, number of transforms</span>

<span class="sd">    Returns:</span>
<span class="sd">        Neural network</span>
<span class="sd">    """</span>

    <span class="c1"># We need these asserts because mean and std can be defined outside, prior to user</span>
    <span class="c1"># input checks.</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">prior_mean</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">float32</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">"Prior mean must have dtype float32, is </span><span class="si">{</span><span class="n">prior_mean</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">."</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">prior_std</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">float32</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">"Prior std must have dtype float32, is </span><span class="si">{</span><span class="n">prior_std</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">."</span>

    <span class="n">standardizing_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">AffineTransform</span><span class="p">(</span>
        <span class="n">shift</span><span class="o">=-</span><span class="n">prior_mean</span> <span class="o">/</span> <span class="n">prior_std</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="n">prior_std</span>
    <span class="p">)</span>

    <span class="n">theta_numel</span> <span class="o">=</span> <span class="n">prior_mean</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">x_o_numel</span> <span class="o">=</span> <span class="n">x_o_shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">theta_numel</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_check_1d_flow_limitations</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"parameter"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"mdn"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">MultivariateGaussianMDN</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">hidden_net</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">x_o_numel</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="p">),</span>
            <span class="n">num_components</span><span class="o">=</span><span class="n">mdn_num_components</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"made"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">standardizing_transform</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">MADEMoG</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">made_num_blocks</span><span class="p">,</span>
            <span class="n">num_mixture_components</span><span class="o">=</span><span class="n">made_num_mixture_components</span><span class="p">,</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"maf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">MaskedAffineAutoregressiveTransform</span><span class="p">(</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
                            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                            <span class="n">context_features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
                            <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">tanh</span><span class="p">,</span>
                            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomPermutation</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">([</span><span class="n">standardizing_transform</span><span class="p">,</span> <span class="n">transform</span><span class="p">,])</span>

        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">theta_numel</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"nsf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">PiecewiseRationalQuadraticCouplingTransform</span><span class="p">(</span>
                            <span class="n">mask</span><span class="o">=</span><span class="n">create_alternating_binary_mask</span><span class="p">(</span>
                                <span class="n">features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                            <span class="p">),</span>
                            <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="n">nets</span><span class="o">.</span><span class="n">ResidualNet</span><span class="p">(</span>
                                <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
                                <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
                                <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                                <span class="n">context_features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
                                <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">activation</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span>
                                <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">tails</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span>
                            <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
                            <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">LULinear</span><span class="p">(</span><span class="n">theta_numel</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">([</span><span class="n">standardizing_transform</span><span class="p">,</span> <span class="n">transform</span><span class="p">,])</span>

        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">theta_numel</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">return</span> <span class="n">neural_net</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="sbi.utils.get_nn_models.likelihood_nn">
<code class="highlight language-python">
sbi.utils.get_nn_models.likelihood_nn<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">theta_shape</span><span class="p">,</span> <span class="n">x_o_shape</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">mdn_num_components</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">made_num_mixture_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">made_num_blocks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">flow_num_transforms</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> </code>
<a class="headerlink" href="#sbi.utils.get_nn_models.likelihood_nn" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<p>Neural likelihood density estimator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code>str</code></td>
<td>
<p>Model, one of maf / mdn / made / nsf</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>theta_numel</code></td>
<td><code></code></td>
<td>
<p>event shape of the prior, number of parameters.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x_o_numel</code></td>
<td><code></code></td>
<td>
<p>number of elements in a single data point.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embedding</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Embedding network</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>hidden_features</code></td>
<td><code>int</code></td>
<td>
<p>For all, number of hidden features</p>
</td>
<td><code>50</code></td>
</tr>
<tr>
<td><code>mdn_num_components</code></td>
<td><code>int</code></td>
<td>
<p>For MDNs only, number of components</p>
</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>made_num_mixture_components</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of mixture components</p>
</td>
<td><code>10</code></td>
</tr>
<tr>
<td><code>made_num_blocks</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of blocks</p>
</td>
<td><code>4</code></td>
</tr>
<tr>
<td><code>flow_num_transforms</code></td>
<td><code>int</code></td>
<td>
<p>For flows only, number of transforms</p>
</td>
<td><code>5</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>nn.Module</code></td>
<td>
<p>Neural network</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/utils/get_nn_models.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">likelihood_nn</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">theta_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">x_o_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">mdn_num_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">made_num_mixture_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">made_num_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">flow_num_transforms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">"""Neural likelihood density estimator</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Model, one of maf / mdn / made / nsf</span>
<span class="sd">        theta_numel: event shape of the prior, number of parameters.</span>
<span class="sd">        x_o_numel: number of elements in a single data point.</span>
<span class="sd">        embedding: Embedding network</span>
<span class="sd">        hidden_features: For all, number of hidden features</span>
<span class="sd">        mdn_num_components: For MDNs only, number of components</span>
<span class="sd">        made_num_mixture_components: For MADEs only, number of mixture components</span>
<span class="sd">        made_num_blocks: For MADEs only, number of blocks</span>
<span class="sd">        flow_num_transforms: For flows only, number of transforms</span>

<span class="sd">    Returns:</span>
<span class="sd">        Neural network</span>
<span class="sd">    """</span>

    <span class="n">theta_numel</span> <span class="o">=</span> <span class="n">theta_shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">x_o_numel</span> <span class="o">=</span> <span class="n">x_o_shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">x_o_numel</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_check_1d_flow_limitations</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"data"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"mdn"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">MultivariateGaussianMDN</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">hidden_net</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">theta_numel</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="p">),</span>
            <span class="n">num_components</span><span class="o">=</span><span class="n">mdn_num_components</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"made"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">MixtureOfGaussiansMADE</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">made_num_blocks</span><span class="p">,</span>
            <span class="n">num_mixture_components</span><span class="o">=</span><span class="n">made_num_mixture_components</span><span class="p">,</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"maf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">MaskedAffineAutoregressiveTransform</span><span class="p">(</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span>
                            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                            <span class="n">context_features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
                            <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">tanh</span><span class="p">,</span>
                            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomPermutation</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">x_o_numel</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"nsf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">PiecewiseRationalQuadraticCouplingTransform</span><span class="p">(</span>
                            <span class="n">mask</span><span class="o">=</span><span class="n">create_alternating_binary_mask</span><span class="p">(</span>
                                <span class="n">features</span><span class="o">=</span><span class="n">x_o_numel</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                            <span class="p">),</span>
                            <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="n">nets</span><span class="o">.</span><span class="n">ResidualNet</span><span class="p">(</span>
                                <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
                                <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
                                <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                                <span class="n">context_features</span><span class="o">=</span><span class="n">theta_numel</span><span class="p">,</span>
                                <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">activation</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span>
                                <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">tails</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span>
                            <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
                            <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">LULinear</span><span class="p">(</span><span class="n">x_o_numel</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">x_o_numel</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">return</span> <span class="n">neural_net</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="sbi.utils.get_nn_models.classifier_nn">
<code class="highlight language-python">
sbi.utils.get_nn_models.classifier_nn<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">theta_shape</span><span class="p">,</span> <span class="n">x_o_shape</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> </code>
<a class="headerlink" href="#sbi.utils.get_nn_models.classifier_nn" title="Permanent link">¶</a></h3>
<div class="doc doc-contents first">
<p>Neural classifier</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code></code></td>
<td>
<p>Model, one of linear / mlp / resnet</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>theta_numel</code></td>
<td><code></code></td>
<td>
<p>event shape of the prior, number of parameters.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>x_o_numel</code></td>
<td><code></code></td>
<td>
<p>number of elements in a single data point.</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hidden_features</code></td>
<td><code>int</code></td>
<td>
<p>For all, number of hidden features</p>
</td>
<td><code>50</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>nn.Module</code></td>
<td>
<p>Neural network</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/utils/get_nn_models.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">classifier_nn</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">theta_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">x_o_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">"""Neural classifier</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Model, one of linear / mlp / resnet</span>
<span class="sd">        theta_numel: event shape of the prior, number of parameters.</span>
<span class="sd">        x_o_numel: number of elements in a single data point.</span>
<span class="sd">        hidden_features: For all, number of hidden features</span>

<span class="sd">    Returns:</span>
<span class="sd">        Neural network</span>
<span class="sd">    """</span>

    <span class="n">theta_numel</span> <span class="o">=</span> <span class="n">theta_shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">x_o_numel</span> <span class="o">=</span> <span class="n">x_o_shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"linear"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">theta_numel</span> <span class="o">+</span> <span class="n">x_o_numel</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"mlp"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">theta_numel</span> <span class="o">+</span> <span class="n">x_o_numel</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"resnet"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">nets</span><span class="o">.</span><span class="n">ResidualNet</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">theta_numel</span> <span class="o">+</span> <span class="n">x_o_numel</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"'model' must be one of ['linear', 'mlp', 'resnet']."</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">neural_net</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav aria-label="Footer" class="md-footer-nav__inner md-grid">
<a class="md-footer-nav__link md-footer-nav__link--prev" href="../contribute/" rel="prev" title="Contribute">
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</div>
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Previous
                </span>
                Contribute
              </div>
</div>
</a>
<a class="md-footer-nav__link md-footer-nav__link--next" href="../credits/" rel="next" title="Credits">
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Next
                </span>
                Credits
              </div>
</div>
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
          Material for MkDocs
        </a>
</div>
<div class="md-footer-social">
<a class="md-footer-social__link" href="https://github.com/mackelab/sbi" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 480 512" xmlns="http://www.w3.org/2000/svg"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/vendor.d710d30a.min.js"></script>
<script src="../assets/javascripts/bundle.5f27aba8.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
<script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.27c6a5e6.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>